# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fg-CJPJhOsCviqb23HZqJjHTlGwTaFHk
"""

import pandas as pd

def filter_csv_columns(input_file: str, output_file: str):
    # Define the columns to keep with their data types
    columns_to_keep = [
        'cian_id', 'city', 'street', 'lat', 'lon', 'price_sq', 'area', 'floor',
        'kitchen_area', 'bathroom_type', 'balconies', 'renovation', 'is_apartment',
        'rooms', 'ceiling_height', 'house_floors', 'house_wall_type', 'lifts',
        'freight_lifts', 'time_on_foot_to_subway', 'build_year'
    ]

    try:
        # Read the CSV file
        df = pd.read_csv(input_file)

        # Check if the necessary columns exist
        missing_columns = [col for col in columns_to_keep if col not in df.columns]
        if missing_columns:
            raise ValueError(f"Missing columns in input file: {missing_columns}")

        # Select only the required columns
        filtered_df = df[columns_to_keep]

        # Save the resulting DataFrame to a new CSV file
        filtered_df.to_csv(output_file, index=False)

        print(f"Filtered data saved to {output_file}")
    except Exception as e:
        print(f"An error occurred: {e}")

# Example usage
input_csv = 'cian_25.11.24.csv'  # Path to your input CSV file
output_csv = 'filtered_output.csv'  # Path to save the filtered CSV
filter_csv_columns(input_csv, output_csv)

import pandas as pd
import numpy as np
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
import joblib
def train_model(csv_file: str, model_file: str):
    # Read the CSV file
    df = pd.read_csv(csv_file)

    # Define features and target
    target = 'price_sq'
    features = [
        'lat', 'lon', 'area', 'floor', 'kitchen_area', 'balconies', 'renovation',
        'is_apartment', 'rooms', 'ceiling_height', 'house_floors', 'lifts',
        'freight_lifts', 'time_on_foot_to_subway', 'build_year', 'city', 'street',
        'bathroom_type', 'house_wall_type'
    ]


    # Preprocess the data
    numeric_features = ['lat', 'lon', 'area', 'floor', 'kitchen_area',
                        'rooms', 'ceiling_height', 'house_floors',
                        'lifts', 'freight_lifts', 'time_on_foot_to_subway', 'build_year']
    categorical_features = ['city', 'renovation', 'balconies','street', 'bathroom_type', 'house_wall_type']
    # Replace commas with dots for all numeric features
    for feature in numeric_features:
        df[feature] = df[feature].replace({',': '.'}, regex=True).astype(float)
        df[feature] = pd.to_numeric(df[feature], errors='coerce')  # Convert to float and handle errors

    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler())
    ])

    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ])

    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_features),
            ('cat', categorical_transformer, categorical_features)
        ]
    )

    # Define the model pipeline
    model = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('regressor', RandomForestRegressor(random_state=42))
    ])

    X = df[features]
    y = df[target]
    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train the model
    model.fit(X_train, y_train)

    # Save the model
    joblib.dump(model, model_file)

    print(f"Model trained and saved to {model_file}")
        # Predictions
    y_pred = model.predict(X_test)

    # Calculate metrics
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    # Print evaluation metrics
    print(f"Model Evaluation:")
    print(f"R-squared: {r2:.4f}")
    print(f"Mean Absolute Error (MAE): {mae:.4f}")
    print(f"Mean Squared Error (MSE): {mse:.4f}")
    print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")

model_file = 'model.pkl'  # Path to save the trained model

train_model('filtered_output.csv', model_file)